{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062d8d6e",
   "metadata": {},
   "source": [
    "# RSNA Intracranial Aneurysm Detection - 3D CNN Pipeline\n",
    "\n",
    "Este notebook implementa un pipeline de entrenamiento y predicción basado en una red neuronal convolucional 3D (3D CNN) usando PyTorch, para la detección y localización de aneurismas cerebrales en el dataset de la competición RSNA. Los datos se leen desde la carpeta `data/` y los resultados se guardan en `output/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 1: Importar librerías y definir rutas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "SERIES_DIR = os.path.join(DATA_DIR, 'series')\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, 'train.csv')\n",
    "OUTPUT_DIR = 'output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e06616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 2: Cargar datos y fusionar localizadores (manteniendo todas las series)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print('Shape train_df:', train_df.shape)\n",
    "display(train_df.head())\n",
    "LOCALIZERS_CSV = os.path.join(DATA_DIR, 'train_localizers.csv')\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "localizers_df = pd.read_csv(LOCALIZERS_CSV)\n",
    "# Fusionar, manteniendo todas las series de train.csv y añadiendo info de localizadores si existe\n",
    "df = pd.merge(train_df, localizers_df, on='SeriesInstanceUID', how='left', suffixes=('', '_localizer'))\n",
    "print('Shape df fusionado:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 3: Dataset y utilidades para 3D CNN\n",
    "def load_dicom_volume(series_uid, target_shape=(64, 128, 128)):\n",
    "    series_path = os.path.join(SERIES_DIR, str(series_uid))\n",
    "    if not os.path.exists(series_path):\n",
    "        return None\n",
    "    dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n",
    "    if not dicom_files:\n",
    "        return None\n",
    "    dicom_files.sort()\n",
    "    slices = []\n",
    "    for f in dicom_files:\n",
    "        dcm = pydicom.dcmread(os.path.join(series_path, f))\n",
    "        img = dcm.pixel_array.astype(np.float32)\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-6)\n",
    "        slices.append(img)\n",
    "    volume = np.stack(slices, axis=0)\n",
    "    # Resize to target_shape\n",
    "    from scipy.ndimage import zoom\n",
    "    factors = [t/s for t, s in zip(target_shape, volume.shape)]\n",
    "    volume = zoom(volume, factors, order=1)\n",
    "    return volume\n",
    "\n",
    "class Aneurysm3DDataset(Dataset):\n",
    "    def __init__(self, df, label_cols=LABEL_COLS, augment=False):\n",
    "        self.df = df\n",
    "        self.label_cols = label_cols\n",
    "        self.augment = augment\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        vol = load_dicom_volume(row['SeriesInstanceUID'])\n",
    "        if vol is None:\n",
    "            vol = np.zeros((64,128,128), dtype=np.float32)\n",
    "        if self.augment and np.random.rand() < 0.5:\n",
    "            vol = np.flip(vol, axis=2).copy()\n",
    "        vol = np.expand_dims(vol, 0)\n",
    "        label = row[self.label_cols].values.astype(np.float32)\n",
    "        return torch.tensor(vol, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 4: Definir modelo 3D CNN\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, out_dim=13):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, 3, padding=1), nn.BatchNorm3d(16), nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(16, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((2,4,4)),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*2*4*4, 128), nn.ReLU(),\n",
    "            nn.Linear(128, out_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sección 5: Entrenamiento de la 3D CNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "df = df.dropna(subset=LABEL_COLS, how='all').reset_index(drop=True)\n",
    "train_idx, val_idx = train_test_split(np.arange(len(df)), test_size=0.2, random_state=42)\n",
    "train_set = Aneurysm3DDataset(df.iloc[train_idx].reset_index(drop=True), augment=True)\n",
    "val_set = Aneurysm3DDataset(df.iloc[val_idx].reset_index(drop=True), augment=False)\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=2, shuffle=False, num_workers=2)\n",
    "model = Simple3DCNN(out_dim=len(LABEL_COLS)).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "best_auc = 0\n",
    "for epoch in range(1, 11):\n",
    "    print(f'Epoch {epoch}')\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    model.eval()\n",
    "    val_losses, preds, targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_losses.append(loss.item())\n",
    "            preds.append(torch.sigmoid(out).cpu().numpy())\n",
    "            targets.append(y.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    aucs = []\n",
    "    for i in range(len(LABEL_COLS)):\n",
    "        try:\n",
    "            auc = roc_auc_score(targets[:,i], preds[:,i])\n",
    "        except:\n",
    "            auc = np.nan\n",
    "        aucs.append(auc)\n",
    "    mean_auc = np.nanmean(aucs)\n",
    "    print(f'Train loss: {np.mean(train_losses):.4f} | Val loss: {np.mean(val_losses):.4f} | Mean AUC: {mean_auc:.4f}')\n",
    "    if mean_auc > best_auc:\n",
    "        best_auc = mean_auc\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_3dcnn.pth'))\n",
    "print('Entrenamiento finalizado. Mejor modelo guardado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e657b",
   "metadata": {},
   "source": [
    "# Sección 6: Predicción con el modelo 3D CNN\n",
    "Para predecir sobre nuevos datos, utiliza el script `scripts/predict_3dcnn.py` o adapta el siguiente ejemplo de código en una celda de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa346792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de predicción sobre test.csv\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scripts.train_3dcnn import Simple3DCNN, load_dicom_volume, LABEL_COLS\n",
    "DATA_DIR = 'data'\n",
    "SERIES_DIR = os.path.join(DATA_DIR, 'series')\n",
    "TEST_CSV = os.path.join(DATA_DIR, 'test.csv')\n",
    "LOCALIZERS_CSV = os.path.join(DATA_DIR, 'train_localizers.csv')\n",
    "OUTPUT_DIR = 'output'\n",
    "\n",
    "# Cargar test.csv y fusionar con localizadores si aplica (aunque normalmente test.csv no tiene localizadores)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "if os.path.exists(LOCALIZERS_CSV):\n",
    "    localizers_df = pd.read_csv(LOCALIZERS_CSV)\n",
    "    df_test = pd.merge(test_df, localizers_df, on='SeriesInstanceUID', how='left', suffixes=('', '_localizer'))\n",
    "else:\n",
    "    df_test = test_df.copy()\n",
    "\n",
    "class Aneurysm3DTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        vol = load_dicom_volume(row['SeriesInstanceUID'])\n",
    "        if vol is None:\n",
    "            vol = np.zeros((64,128,128), dtype=np.float32)\n",
    "        vol = np.expand_dims(vol, 0)\n",
    "        return torch.tensor(vol, dtype=torch.float32), row['SeriesInstanceUID']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_set = Aneurysm3DTestDataset(df_test)\n",
    "test_loader = DataLoader(test_set, batch_size=2, shuffle=False, num_workers=2)\n",
    "model = Simple3DCNN(out_dim=len(LABEL_COLS)).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best_3dcnn.pth'), map_location=device))\n",
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for x, series_uids in test_loader:\n",
    "        x = x.to(device)\n",
    "        out = torch.sigmoid(model(x)).cpu().numpy()\n",
    "        for i, uid in enumerate(series_uids):\n",
    "            row = {'SeriesInstanceUID': uid}\n",
    "            for j, col in enumerate(LABEL_COLS):\n",
    "                row[col] = out[i, j]\n",
    "            results.append(row)\n",
    "pred_df = pd.DataFrame(results)\n",
    "pred_df.to_csv(os.path.join(OUTPUT_DIR, '3dcnn_predictions.csv'), index=False)\n",
    "print('Predicciones guardadas en', os.path.join(OUTPUT_DIR, '3dcnn_predictions.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba05477",
   "metadata": {},
   "source": [
    "# Fin del pipeline 3D CNN\n",
    "\n",
    "Todos los modelos y el resumen de resultados se han guardado en `/kaggle/working` y pueden descargarse desde la interfaz de Kaggle tras la ejecución del notebook."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
